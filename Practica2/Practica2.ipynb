{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Practica 2**\n",
    "#### _Alberto García Doménech - Pablo Daurell Marina_ (Grupo 10)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 (Análisis de sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"yelp_labelled.txt\", sep='\\t', names=['Review', 'Valoration'])\n",
    "data = df.to_numpy()[:, 0]\n",
    "target = df.to_numpy()[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow... Loved this place. 1\n",
      "Crust is not good. 0\n",
      "Not tasty and the texture was just nasty. 0\n",
      "Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. 1\n",
      "The selection on the menu was great and so were the prices. 1\n",
      "Now I am getting angry and I want my damn pho. 0\n",
      "Honeslty it didn't taste THAT fresh.) 0\n",
      "The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer. 0\n",
      "The fries were great too. 1\n",
      "A great touch. 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(data[i], target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  750\n",
      "Test size:  250\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size: \", train_data.size)\n",
    "print(\"Test size: \", test_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "def write_terms (feature_names, data, vector_data, index):\n",
    "    '''\n",
    "    Escribe los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - data: lista de mensajes original (si data==None no se muestra el mensaje original)\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    \n",
    "    # mostrar mensaje original\n",
    "    if data.any():\n",
    "        print('Mensaje', index, ':', data[index])\n",
    "    \n",
    "    # mostrar términos que aparecen en el mensaje vectorizado\n",
    "    print('Mensaje', index, 'vectorizado:', terminos.compressed(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Bolsas de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizerb\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bolsa de palabras binaria y n-gramas (1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una bolsa de palabras con monogramas (solo tenemos en cuenta la probabilidad de una palabra, independientemente del resto) y que tenga en cuenta si una palabra aprece o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510\n"
     ]
    }
   ],
   "source": [
    "binary_monogram_vectorizer = CountVectorizer(stop_words='english', binary=True, ngram_range = (1,1)) \n",
    "train_vector_data = vectorizer.fit_transform(train_data)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bolsa de palabras con TF-IDF y n-gramas (1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una bolsa de palabras con monogramas (solo tenemos en cuenta la probabilidad de una palabra, independientemente del resto) y que tenga en cuenta la frecuencia de aparición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', binary=False, ngram_range = (1,1))\n",
    "train_vector_data = vectorizer.fit_transform(train_data)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez generada la bolsa de palabras, convertimos los valores de frecuencia a TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 1510)\n"
     ]
    }
   ],
   "source": [
    "tfider = TfidfTransformer()\n",
    "train_preprocessed = tfider.fit_transform(train_vector_data)\n",
    "print(train_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos los datos de test al modelo de bolsa de palabra que acabamos de crear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 1510)\n"
     ]
    }
   ],
   "source": [
    "test_vector_data = vectorizer.transform(test_data)\n",
    "test_preprocessed = tfider.transform(test_vector_data)\n",
    "print(test_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje 10 : The cashew cream sauce was bland and the vegetables were undercooked.\n",
      "Mensaje 10 vectorizado: ['bland' 'cashew' 'cream' 'sauce' 'undercooked' 'vegetables'] \n",
      "\n",
      "Mensaje 100 : Now this dish was quite flavourful.\n",
      "Mensaje 100 vectorizado: ['dish' 'flavourful' 'quite'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_terms(feature_names, train_data, train_preprocessed, 10)\n",
    "write_terms(feature_names, train_data, train_preprocessed, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bolsa de palabras binarias y n-gramas (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4347\n"
     ]
    }
   ],
   "source": [
    "binary_bigram_vectorizer = CountVectorizer(stop_words='english', binary=True, ngram_range = (1,2))\n",
    "train_vector_data = vectorizer.fit_transform(X_train)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bolsa de palabras con TF-IDF y n-gramas (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4347\n"
     ]
    }
   ],
   "source": [
    "tfidf_bigram_vectorizer = CountVectorizer(stop_words='english', binary=False ,ngram_range = (1,2))\n",
    "train_vector_data = vectorizer.fit_transform(X_train)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "def write_terms (feature_names, data, vector_data, index):\n",
    "    '''\n",
    "    Escribe los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - data: lista de mensajes original (si data==None no se muestra el mensaje original)\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    \n",
    "    # mostrar mensaje original\n",
    "    if data.any():\n",
    "        print('Mensaje', index, ':', data[index])\n",
    "    \n",
    "    # mostrar términos que aparecen en el mensaje vectorizado\n",
    "    print('Mensaje', index, 'vectorizado:', terminos.compressed(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_terms(feature_names, X_train, train_vector_data, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
